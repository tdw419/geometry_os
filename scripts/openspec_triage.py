#!/usr/bin/env python3
"""
OpenSpec Backlog Triage Tool

Scans openspec/changes/ directory, identifies noise directories (15+ files),
archives them with manifest tracking, and generates ASCII dashboard.

Usage:
    python scripts/openspec_triage.py --dry-run
    python scripts/openspec_triage.py --interactive
    python scripts/openspec_triage.py --rollback openspec/manifests/archive_xxx.json
"""

import argparse
import re
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional


# =============================================================================
# Constants
# =============================================================================

# Pattern for SOLUTION files generated by AI exploration
SOLUTION_PATTERN = re.compile(r"^SOLUTION_[A-Z0-9]+\.md$")


# =============================================================================
# Data Classes
# =============================================================================

@dataclass
class DirectoryMetrics:
    """Metrics collected for a single proposal directory."""
    path: Path
    total_files: int
    solution_count: int
    has_proposal: bool
    has_design: bool
    system: str  # Inferred from keywords


@dataclass
class ScanResult:
    """Result of scanning openspec/changes/ directory."""
    noise_dirs: List[DirectoryMetrics]  # >= threshold files
    clean_dirs: List[DirectoryMetrics]  # < threshold files
    total_scanned: int


@dataclass
class ProposalCategory:
    """Category and priority inferred for a proposal."""
    system: str
    priority: int  # 1-5 (1 = highest, based on NORTH_STAR alignment)
    status: str    # "active", "likely-complete", "unknown"


@dataclass
class ArchiveEntry:
    """Record of a single archived directory."""
    original_path: Path
    archive_path: Path
    timestamp: str
    file_count: int
    system: str
    extracted_content: Dict[str, str] = field(default_factory=dict)  # filename -> content


@dataclass
class ArchiveManifest:
    """Manifest tracking all archived directories in a single run."""
    manifest_id: str
    created_at: str
    entries: List[ArchiveEntry] = field(default_factory=list)
    dry_run: bool = True


# =============================================================================
# Categorizer Component
# =============================================================================

# System keywords with priority order (from NORTH_STAR.md)
# Priority: visual-shell=1, swarm=2, evolution=2, memory=3, neb=4, infra=5
SYSTEM_KEYWORDS = {
    "visual-shell": {
        "priority": 1,
        "keywords": ["visual", "shell", "pixi", "desktop", "infinite-map", "window", "gui", "terminal", "compositor"]
    },
    "swarm": {
        "priority": 2,
        "keywords": ["swarm", "guild", "agent", "ghost", "mentor", "delegate", "a2a"]
    },
    "evolution": {
        "priority": 2,
        "keywords": ["evolution", "daemon", "self-improv", "recursive", "tectonic", "rectification"]
    },
    "memory": {
        "priority": 3,
        "keywords": ["memory", "episodic", "context", "knowledge", "hippocampus", "embedding"]
    },
    "neb": {
        "priority": 4,
        "keywords": ["neb", "neural-event", "event-bus", "pubsub", "resonance"]
    },
    "infrastructure": {
        "priority": 5,
        "keywords": ["build", "deploy", "ci", "docker", "config", "infra", "test"]
    }
}


def categorize_proposal(metrics: DirectoryMetrics, project_root: Path) -> ProposalCategory:
    """
    Categorize a proposal by system and assign priority.

    Args:
        metrics: DirectoryMetrics for the proposal
        project_root: Root path of the project (for git checks)

    Returns:
        ProposalCategory with system, priority, and status
    """
    dir_name = metrics.path.name.lower()

    # Match against system keywords (priority order)
    best_system = "unknown"
    best_priority = 99

    for system, config in SYSTEM_KEYWORDS.items():
        for keyword in config["keywords"]:
            if keyword in dir_name:
                if config["priority"] < best_priority:
                    best_system = system
                    best_priority = config["priority"]
                break  # Found match for this system, move to next

    # Default to infrastructure if unknown
    if best_system == "unknown":
        best_system = "infrastructure"
        best_priority = 5

    # Check git status (stub for POC)
    status = check_git_implementation(metrics.path.name, project_root)

    return ProposalCategory(
        system=best_system,
        priority=best_priority,
        status=status
    )


def check_git_implementation(dir_name: str, project_root: Path) -> str:
    """
    Check git history for implementation evidence.

    POC stub: Always returns "unknown".
    Phase 2 will implement actual git log checking.
    """
    # TODO: Implement in Phase 2
    # git log --grep=<proposal-name> --oneline
    return "unknown"


# =============================================================================
# Scanner Component
# =============================================================================

def scan_changes(base_path: Path, threshold: int = 15) -> ScanResult:
    """
    Scan openspec/changes/ directory for noise candidates.

    Args:
        base_path: Path to openspec/changes/ directory
        threshold: Minimum file count to consider a directory as noise (default: 15)

    Returns:
        ScanResult with noise_dirs (>= threshold) and clean_dirs (< threshold)
    """
    noise_dirs: List[DirectoryMetrics] = []
    clean_dirs: List[DirectoryMetrics] = []

    if not base_path.exists():
        # Return empty result if directory doesn't exist
        return ScanResult(
            noise_dirs=noise_dirs,
            clean_dirs=clean_dirs,
            total_scanned=0
        )

    # Iterate through all subdirectories
    for item in base_path.iterdir():
        if not item.is_dir():
            continue

        # Count files and detect SOLUTION pattern
        total_files = 0
        solution_count = 0
        has_proposal = False
        has_design = False

        for file in item.iterdir():
            if file.is_file():
                total_files += 1

                # Check for SOLUTION pattern
                if SOLUTION_PATTERN.match(file.name):
                    solution_count += 1

                # Check for proposal.md and design.md
                if file.name.lower() == "proposal.md":
                    has_proposal = True
                elif file.name.lower() == "design.md":
                    has_design = True

        # Infer system from directory name (placeholder for categorizer)
        system = _infer_system_from_name(item.name)

        # Create metrics
        metrics = DirectoryMetrics(
            path=item,
            total_files=total_files,
            solution_count=solution_count,
            has_proposal=has_proposal,
            has_design=has_design,
            system=system
        )

        # Classify as noise or clean
        if total_files >= threshold:
            noise_dirs.append(metrics)
        else:
            clean_dirs.append(metrics)

    # Sort noise dirs by file count (highest first)
    noise_dirs.sort(key=lambda m: m.total_files, reverse=True)

    # Sort clean dirs alphabetically
    clean_dirs.sort(key=lambda m: m.path.name)

    return ScanResult(
        noise_dirs=noise_dirs,
        clean_dirs=clean_dirs,
        total_scanned=len(noise_dirs) + len(clean_dirs)
    )


def _infer_system_from_name(dir_name: str) -> str:
    """
    Infer system from directory name using keyword matching.

    This is a helper for the scanner. The categorizer component provides
    more sophisticated classification with priority assignment.
    """
    dir_lower = dir_name.lower()

    # System keyword mappings (order matters for priority)
    system_keywords = {
        "visual-shell": ["visual-shell", "visual_shell", "visualshell", "desktop", "pixi", "infinite-desktop"],
        "swarm": ["swarm", "guild", "agent", "neb", "neural-event"],
        "evolution": ["evolution", "daemon", "self-improv", "recursive"],
        "memory": ["memory", "episodic", "context", "knowledge"],
        "neb": ["neb", "event-bus", "pubsub"],
        "intelligence": ["intelligence", "lm-studio", "llm", "socratic"],
        "infrastructure": ["infra", "build", "deploy", "ci", "cd"]
    }

    for system, keywords in system_keywords.items():
        for keyword in keywords:
            if keyword in dir_lower:
                return system

    return "unknown"


# =============================================================================
# Archiver Component
# =============================================================================

def archive_directory(
    metrics: DirectoryMetrics,
    archive_base: Path,
    dry_run: bool = True
) -> ArchiveEntry:
    """
    Archive a noise directory to archive/noise/<system>/.

    Args:
        metrics: DirectoryMetrics for the directory to archive
        archive_base: Base path for archives (e.g., openspec/archive/)
        dry_run: If True, don't actually move files

    Returns:
        ArchiveEntry with archive metadata
    """
    timestamp = datetime.now().isoformat()

    # Construct archive path: archive/noise/<system>/<dir_name>/
    archive_path = archive_base / "noise" / metrics.system / metrics.path.name

    # Extract valuable content
    extracted = extract_valuable_content(metrics.path)

    # Create archive entry
    entry = ArchiveEntry(
        original_path=metrics.path,
        archive_path=archive_path,
        timestamp=timestamp,
        file_count=metrics.total_files,
        system=metrics.system,
        extracted_content=extracted
    )

    # In dry-run mode, don't actually move files
    if not dry_run:
        # TODO: Implement actual file moves in Phase 2
        pass

    return entry


def extract_valuable_content(dir_path: Path) -> Dict[str, str]:
    """
    Extract proposal.md and design.md content from a directory.

    Args:
        dir_path: Path to the proposal directory

    Returns:
        Dict mapping filename to content for valuable files found
    """
    extracted: Dict[str, str] = {}

    for filename in ["proposal.md", "design.md"]:
        file_path = dir_path / filename
        if file_path.exists():
            try:
                extracted[filename] = file_path.read_text(encoding="utf-8")
            except Exception:
                # Skip files that can't be read
                pass

    return extracted


def generate_manifest(entries: List[ArchiveEntry], dry_run: bool) -> ArchiveManifest:
    """
    Generate a manifest for archive operations.

    Args:
        entries: List of ArchiveEntry objects
        dry_run: Whether this is a dry-run

    Returns:
        ArchiveManifest with unique ID and all entries
    """
    timestamp = datetime.now()
    manifest_id = f"archive_{timestamp.strftime('%Y%m%d_%H%M%S')}"

    return ArchiveManifest(
        manifest_id=manifest_id,
        created_at=timestamp.isoformat(),
        entries=entries,
        dry_run=dry_run
    )


def write_manifest(manifest: ArchiveManifest, output_dir: Path) -> Path:
    """
    Write manifest to JSON file.

    Args:
        manifest: ArchiveManifest to write
        output_dir: Directory for manifests (e.g., openspec/manifests/)

    Returns:
        Path to the written manifest file
    """
    output_dir.mkdir(parents=True, exist_ok=True)

    manifest_path = output_dir / f"{manifest.manifest_id}.json"

    # Convert to dict for JSON serialization
    manifest_dict = {
        "manifest_id": manifest.manifest_id,
        "created_at": manifest.created_at,
        "dry_run": manifest.dry_run,
        "entries": [
            {
                "original_path": str(e.original_path),
                "archive_path": str(e.archive_path),
                "timestamp": e.timestamp,
                "file_count": e.file_count,
                "system": e.system,
                "extracted_content": e.extracted_content
            }
            for e in manifest.entries
        ]
    }

    import json
    manifest_path.write_text(json.dumps(manifest_dict, indent=2), encoding="utf-8")

    return manifest_path


def rollback_manifest(manifest_path: Path, archive_base: Path) -> int:
    """
    Restore directories from a manifest file.

    Args:
        manifest_path: Path to the manifest JSON file
        archive_base: Base path for archives

    Returns:
        Number of directories restored
    """
    import json
    import shutil

    if not manifest_path.exists():
        return 0

    manifest_data = json.loads(manifest_path.read_text(encoding="utf-8"))
    restored = 0

    for entry in manifest_data.get("entries", []):
        original_path = Path(entry["original_path"])
        archive_path = Path(entry["archive_path"])

        if not archive_path.exists():
            continue  # Skip if archive doesn't exist

        if original_path.exists():
            continue  # Skip if original already exists (conflict)

        try:
            shutil.move(str(archive_path), str(original_path))
            restored += 1
        except Exception:
            pass  # Log error but continue

    # Move manifest to completed/
    completed_dir = manifest_path.parent / "completed"
    completed_dir.mkdir(parents=True, exist_ok=True)
    try:
        shutil.move(str(manifest_path), str(completed_dir / manifest_path.name))
    except Exception:
        pass

    return restored


# =============================================================================
# Dashboard Generator Component
# =============================================================================

def format_ascii_table(rows: List[List[str]], headers: List[str]) -> str:
    """
    Format data as ASCII table.

    Args:
        rows: List of row data (each row is list of strings)
        headers: Column headers

    Returns:
        Formatted ASCII table string
    """
    # Calculate column widths
    widths = [len(h) for h in headers]
    for row in rows:
        for i, cell in enumerate(row):
            if i < len(widths):
                widths[i] = max(widths[i], len(cell))

    # Build separator line
    separator = "+" + "+".join("-" * (w + 2) for w in widths) + "+"

    # Build header row
    header_row = "|" + "|".join(f" {h:<{widths[i]}} " for i, h in enumerate(headers)) + "|"

    # Build data rows
    data_rows = []
    for row in rows:
        cells = []
        for i, cell in enumerate(row):
            if i < len(widths):
                cells.append(f" {cell:<{widths[i]}} ")
            else:
                cells.append(f" {cell} ")
        data_rows.append("|" + "|".join(cells) + "|")

    return "\n".join([separator, header_row, separator] + data_rows + [separator])


def generate_dashboard(
    clean_dirs: List[DirectoryMetrics],
    categories: Dict[str, ProposalCategory],
    archived_count: int,
    manifest_path: Optional[Path],
    output_path: Path
) -> None:
    """
    Generate ASCII dashboard at output_path.

    Args:
        clean_dirs: List of clean (non-archived) directories
        categories: Dict mapping dir name to ProposalCategory
        archived_count: Number of directories archived
        manifest_path: Path to manifest file (or None)
        output_path: Where to write the dashboard
    """
    lines = []
    lines.append("=" * 64)
    lines.append("       OPENSPEC BACKLOG TRIAGE SUMMARY")
    lines.append(f"       Generated: {datetime.now().isoformat()}")
    lines.append("=" * 64)
    lines.append("")

    # Archived section
    lines.append("NOISE ARCHIVED")
    lines.append("-" * 14)
    lines.append(f"Total archived:    {archived_count} directories")
    if manifest_path:
        lines.append(f"Manifest:          {manifest_path}")
    lines.append("")

    # System counts
    system_counts: Dict[str, int] = {}
    for metrics in clean_dirs:
        cat = categories.get(metrics.path.name)
        system = cat.system if cat else metrics.system
        system_counts[system] = system_counts.get(system, 0) + 1

    lines.append("REMAINING BACKLOG")
    lines.append("-" * 17)

    # Build table rows
    rows = []
    total = 0
    for system in ["visual-shell", "swarm", "evolution", "memory", "neb", "infrastructure", "unknown"]:
        count = system_counts.get(system, 0)
        if count > 0:
            priority = {"visual-shell": 1, "swarm": 2, "evolution": 2, "memory": 3, "neb": 4}.get(system, 5)
            rows.append([system, str(count), str(priority)])
            total += count

    if rows:
        lines.append(format_ascii_table(rows, ["System", "Count", "Priority"]))
    lines.append("")

    # Top 10 actionable
    lines.append("TOP 10 ACTIONABLE")
    lines.append("-" * 16)

    # Sort by file count (fewer = cleaner = higher priority)
    sorted_clean = sorted(clean_dirs, key=lambda m: m.total_files)[:10]
    for i, metrics in enumerate(sorted_clean, 1):
        cat = categories.get(metrics.path.name)
        system = cat.system if cat else metrics.system
        lines.append(f"{i}. [{system}] {metrics.path.name} ({metrics.total_files} files)")

    lines.append("")
    lines.append("=" * 64)
    if manifest_path:
        lines.append(f"Run: python scripts/openspec_triage.py --rollback {manifest_path} to undo")
    lines.append("=" * 64)

    # Write to file
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text("\n".join(lines), encoding="utf-8")


# =============================================================================
# Main Entry Point
# =============================================================================

def main() -> int:
    """Main entry point for the triage tool."""
    parser = argparse.ArgumentParser(
        description="OpenSpec Backlog Triage Tool - Archive noise directories and prioritize proposals",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Preview noise directories without archiving
  python scripts/openspec_triage.py --dry-run

  # Interactive archive (prompt for each)
  python scripts/openspec_triage.py --interactive

  # Custom threshold
  python scripts/openspec_triage.py --threshold 20 --dry-run

  # Rollback last archive
  python scripts/openspec_triage.py --rollback openspec/manifests/archive_20260225.json
"""
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Generate manifest without moving files"
    )
    parser.add_argument(
        "--interactive",
        action="store_true",
        help="Prompt for each archive decision"
    )
    parser.add_argument(
        "--threshold",
        type=int,
        default=15,
        help="Noise threshold (default: 15 files)"
    )
    parser.add_argument(
        "--rollback",
        type=str,
        metavar="FILE",
        help="Restore from manifest file"
    )
    parser.add_argument(
        "--changes-dir",
        type=str,
        default="./openspec/changes/",
        help="Path to openspec/changes/ (default: ./openspec/changes/)"
    )
    parser.add_argument(
        "--archive-dir",
        type=str,
        default="./openspec/archive/",
        help="Path to archive root (default: ./openspec/archive/)"
    )
    parser.add_argument(
        "--output",
        type=str,
        default=".geometry/triage_summary.txt",
        help="Dashboard output path (default: .geometry/triage_summary.txt)"
    )
    parser.add_argument(
        "-q", "--quiet",
        action="store_true",
        help="Minimal output"
    )
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Detailed logging"
    )

    args = parser.parse_args()

    # Convert paths
    changes_dir = Path(args.changes_dir)
    archive_dir = Path(args.archive_dir)
    output_path = Path(args.output)
    project_root = Path.cwd()

    # Handle rollback mode
    if args.rollback:
        manifest_file = Path(args.rollback)
        if not manifest_file.exists():
            print(f"ERROR: Manifest file not found: {manifest_file}")
            return 1
        count = rollback_manifest(manifest_file, archive_dir)
        print(f"Rollback complete: {count} directories restored")
        return 0

    # Print header
    if not args.quiet:
        print("OpenSpec Backlog Triage Tool")
        print(f"Threshold: {args.threshold} files")
        print(f"Changes dir: {changes_dir}")
        print(f"Dry run: {args.dry_run}")
        print()

    # Step 1: Scan changes directory
    if args.verbose:
        print("Scanning changes directory...")
    result = scan_changes(changes_dir, args.threshold)

    if not args.quiet:
        print(f"Found {result.total_scanned} directories")
        print(f"  Noise (>= {args.threshold} files): {len(result.noise_dirs)}")
        print(f"  Clean (< {args.threshold} files): {len(result.clean_dirs)}")
        print()

    # Step 2: Categorize clean proposals
    categories: Dict[str, ProposalCategory] = {}
    for metrics in result.clean_dirs:
        categories[metrics.path.name] = categorize_proposal(metrics, project_root)

    # Step 3: Archive noise directories (dry-run or actual)
    archive_entries: List[ArchiveEntry] = []
    for metrics in result.noise_dirs:
        if args.interactive and not args.dry_run:
            response = input(f"Archive {metrics.path.name}? ({metrics.total_files} files) [y/N]: ")
            if response.lower() != 'y':
                if args.verbose:
                    print(f"  Skipped: {metrics.path.name}")
                continue

        entry = archive_directory(metrics, archive_dir, dry_run=args.dry_run)
        archive_entries.append(entry)

        if args.verbose:
            print(f"  {'[DRY-RUN] ' if args.dry_run else ''}Archived: {metrics.path.name} -> {entry.archive_path}")

    # Step 4: Generate manifest
    manifest = generate_manifest(archive_entries, dry_run=args.dry_run)
    manifest_path = write_manifest(manifest, archive_dir / "manifests")

    if not args.quiet:
        print(f"\nManifest: {manifest_path}")

    # Step 5: Generate dashboard
    generate_dashboard(
        clean_dirs=result.clean_dirs,
        categories=categories,
        archived_count=len(archive_entries),
        manifest_path=manifest_path,
        output_path=output_path
    )

    if not args.quiet:
        print(f"Dashboard: {output_path}")
        print("\nTop 5 noise candidates:")
        for i, metrics in enumerate(result.noise_dirs[:5], 1):
            print(f"  {i}. {metrics.path.name} ({metrics.total_files} files, {metrics.solution_count} SOLUTION)")

    return 0


if __name__ == "__main__":
    exit(main())
