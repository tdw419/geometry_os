{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis with Neural Heatmap API\n",
    "\n",
    "This notebook demonstrates advanced correlation analysis capabilities.\n",
    "\n",
    "## What You'll Learn\n",
    "- Download and analyze correlation matrices\n",
    "- Filter correlations by layers or models\n",
    "- Visualize multi-model comparisons\n",
    "- Export correlation data for external analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from neural_heatmap import NeuralHeatmapClient, connect, CorrelationMatrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def connect_to_server():\n",
    "    client = await connect(\"http://localhost:8080\")\n",
    "    if client.connected:\n",
    "        print(\"✅ Connected to Neural Heatmap server\")\n",
    "    return client\n",
    "\n",
    "client = await connect_to_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Full Correlation Matrix\n",
    "\n",
    "Get the complete correlation matrix with all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_full_matrix():\n",
    "    # Get correlation matrix as DataFrame\n",
    "    df = await client.get_correlation_matrix(as_dataframe=True)\n",
    "    \n",
    "    print(f\"Correlation Matrix Shape: {df.shape}\")\n",
    "    print(f\"\\nLayers: {list(df.columns)}\")\n",
    "    print(f\"\\nCorrelation Matrix Summary:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "correlation_df = await download_full_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Correlation Matrix with Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_heatmap(df, title=\"Neural Layer Correlation Matrix\"):\n",
    "    \"\"\"Create a beautiful correlation heatmap\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Create heatmap with annotations\n",
    "    sns.heatmap(\n",
    "        df,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='RdBu_r',\n",
    "        center=0,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"shrink\": 0.8, \"label\": \"Correlation\"},\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation_heatmap(correlation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Strong Correlations\n",
    "\n",
    "Find the strongest positive and negative correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_strong_correlations(df, threshold=0.7):\n",
    "    \"\"\"Find strong correlations above threshold\"\"\"\n",
    "    # Get upper triangle (excluding diagonal)\n",
    "    mask = np.triu(np.ones_like(df, dtype=bool), k=1)\n",
    "    upper_tri = df.where(mask)\n",
    "    \n",
    "    # Find correlations above threshold\n",
    "    strong_pos = []\n",
    "    strong_neg = []\n",
    "    \n",
    "    for col in upper_tri.columns:\n",
    "        for idx in upper_tri.index:\n",
    "            val = upper_tri.loc[idx, col]\n",
    "            if pd.notna(val):\n",
    "                if val >= threshold:\n",
    "                    strong_pos.append((idx, col, val))\n",
    "                elif val <= -threshold:\n",
    "                    strong_neg.append((idx, col, val))\n",
    "    \n",
    "    # Sort by correlation strength\n",
    "    strong_pos.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    strong_neg.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    \n",
    "    print(f\"Strong Positive Correlations (≥{threshold}):\")\n",
    "    for layer1, layer2, corr in strong_pos[:10]:\n",
    "        print(f\"  {layer1} ↔ {layer2}: {corr:.3f}\")\n",
    "    \n",
    "    print(f\"\\nStrong Negative Correlations (≤-{threshold}):\")\n",
    "    for layer1, layer2, corr in strong_neg[:10]:\n",
    "        print(f\"  {layer1} ↔ {layer2}: {corr:.3f}\")\n",
    "    \n",
    "    return strong_pos, strong_neg\n",
    "\n",
    "strong_pos, strong_neg = find_strong_correlations(correlation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter by Specific Layers\n",
    "\n",
    "Get correlations for a subset of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_filtered_correlations(layer_ids):\n",
    "    \"\"\"Get correlation matrix for specific layers\"\"\"\n",
    "    # Apply filter\n",
    "    await client.set_filter(layer_ids=layer_ids)\n",
    "    \n",
    "    # Get filtered correlation matrix\n",
    "    df = await client.get_correlation_matrix(as_dataframe=True)\n",
    "    \n",
    "    print(f\"Filtered Correlation Matrix ({len(layer_ids)} layers):\")\n",
    "    print(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example: Get correlations for first 5 layers\n",
    "all_layers = list(correlation_df.columns)\n",
    "selected_layers = all_layers[:5]\n",
    "\n",
    "filtered_df = await get_filtered_correlations(selected_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Model Comparison\n",
    "\n",
    "Compare correlations across multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def compare_models(model_ids):\n",
    "    \"\"\"Compare correlations across multiple models\"\"\"\n",
    "    comparison = await client.compare_models(\n",
    "        model_ids=model_ids,\n",
    "        metrics=[\"correlation\", \"similarity\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"Multi-Model Comparison ({len(model_ids)} models):\")\n",
    "    print(json.dumps(comparison, indent=2))\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "# Example comparison\n",
    "# comparison = await compare_models([\"model1\", \"model2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hierarchical Clustering of Layers\n",
    "\n",
    "Use hierarchical clustering to group similar layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def plot_hierarchical_clustering(df):\n",
    "    \"\"\"Create dendrogram showing layer similarity\"\"\"\n",
    "    # Convert correlation to distance (1 - correlation)\n",
    "    distance_matrix = 1 - df.abs()\n",
    "    \n",
    "    # Get condensed distance matrix\n",
    "    dist_array = squareform(distance_matrix.values)\n",
    "    \n",
    "    # Perform hierarchical clustering\n",
    "    linkage_matrix = linkage(dist_array, method='average')\n",
    "    \n",
    "    # Plot dendrogram\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    dendrogram(\n",
    "        linkage_matrix,\n",
    "        labels=df.columns,\n",
    "        ax=ax,\n",
    "        leaf_rotation=90,\n",
    "        leaf_font_size=10\n",
    "    )\n",
    "    ax.set_title('Hierarchical Clustering of Neural Layers', fontsize=14)\n",
    "    ax.set_xlabel('Layers')\n",
    "    ax.set_ylabel('Distance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_hierarchical_clustering(correlation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Network Visualization\n",
    "\n",
    "Create a network graph showing layer relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import networkx as nx\n",
    "    \n",
    "    def plot_correlation_network(df, threshold=0.5):\n",
    "        \"\"\"Create network graph of layer correlations\"\"\"\n",
    "        # Create graph\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Add nodes\n",
    "        for layer in df.columns:\n",
    "            G.add_node(layer)\n",
    "        \n",
    "        # Add edges for strong correlations\n",
    "        for i, col1 in enumerate(df.columns):\n",
    "            for col2 in df.columns[i+1:]:\n",
    "                corr = df.loc[col1, col2]\n",
    "                if abs(corr) >= threshold:\n",
    "                    # Edge width based on correlation strength\n",
    "                    width = abs(corr) * 3\n",
    "                    # Color based on positive/negative\n",
    "                    color = 'green' if corr > 0 else 'red'\n",
    "                    G.add_edge(col1, col2, width=width, color=color)\n",
    "        \n",
    "        # Draw graph\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "        \n",
    "        # Draw edges\n",
    "        edges = G.edges(data=True)\n",
    "        nx.draw_networkx_edges(\n",
    "            G, pos,\n",
    "            width=[e[2]['width'] for e in edges],\n",
    "            edge_color=[e[2]['color'] for e in edges],\n",
    "            alpha=0.6,\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        # Draw nodes\n",
    "        nx.draw_networkx_nodes(\n",
    "            G, pos,\n",
    "            node_color='lightblue',\n",
    "            node_size=1000,\n",
    "            alpha=0.8,\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        # Draw labels\n",
    "        nx.draw_networkx_labels(G, pos, font_size=10, ax=ax)\n",
    "        \n",
    "        ax.set_title(f'Neural Layer Correlation Network (threshold={threshold})', fontsize=14)\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    plot_correlation_network(correlation_df, threshold=0.5)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"NetworkX not installed. Install with: pip install networkx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Correlation Data\n",
    "\n",
    "Export correlation data in multiple formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def export_correlation_data():\n",
    "    \"\"\"Export correlation data in multiple formats\"\"\"\n",
    "    export_dir = Path(\"./correlation_analysis\")\n",
    "    export_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Export to CSV\n",
    "    await client.download_correlation_matrix(\n",
    "        export_dir / \"correlation_matrix.csv\"\n",
    "    )\n",
    "    print(\"✅ Exported correlation_matrix.csv\")\n",
    "    \n",
    "    # Export to JSON\n",
    "    matrix = await client.get_correlation_matrix()\n",
    "    with open(export_dir / \"correlation_matrix.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"matrix\": matrix.matrix,\n",
    "            \"labels\": matrix.labels,\n",
    "            \"timestamp\": matrix.timestamp,\n",
    "            \"metadata\": matrix.metadata\n",
    "        }, f, indent=2)\n",
    "    print(\"✅ Exported correlation_matrix.json\")\n",
    "    \n",
    "    # Export analysis results\n",
    "    analysis = {\n",
    "        \"strong_positive\": [(l1, l2, float(c)) for l1, l2, c in strong_pos],\n",
    "        \"strong_negative\": [(l1, l2, float(c)) for l1, l2, c in strong_neg]\n",
    "    }\n",
    "    with open(export_dir / \"correlation_analysis.json\", \"w\") as f:\n",
    "        json.dump(analysis, f, indent=2)\n",
    "    print(\"✅ Exported correlation_analysis.json\")\n",
    "\n",
    "await export_correlation_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def cleanup():\n",
    "    await client.clear_filter()\n",
    "    await client.disconnect()\n",
    "    print(\"✅ Disconnected from server\")\n",
    "\n",
    "await cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- How to download and visualize correlation matrices\n",
    "- Techniques for analyzing strong correlations\n",
    "- How to filter correlations by specific layers\n",
    "- Multi-model comparison methods\n",
    "- Hierarchical clustering of neural layers\n",
    "- Network visualization of correlations\n",
    "- Exporting correlation data for external analysis\n",
    "\n",
    "## Next Steps\n",
    "- `03_temporal_patterns.ipynb` - Analyze temporal patterns in neural activity\n",
    "- `05_custom_workflows.ipynb` - Build custom analysis workflows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
