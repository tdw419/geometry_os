# OpenSpec Proposal: PostgreSQL Hippocampus Integration

## Change ID: `042_postgresql_hippocampus`

**Status**: Proposed  
**Phase**: Phase 26  
**Created**: January 22, 2026  
**Estimated Completion**: February 5, 2026

---

## Motivation

### Problem Statement

Geometry OS currently implements a sophisticated visual substrate where "The Screen is the Hard Drive" and every file is a pixel. However, the system suffers from **short-term memory limitations**:

1. **Ephemeral Thought Pixels**: Tokens generated by LM Studio are visualized on the Infinite Map but lost after the session ends
2. **No Semantic Persistence**: Spatial proximity (Hilbert coordinates) doesn't capture semantic relationships
3. **Limited Context**: Visual agents cannot recall past thoughts or patterns from previous sessions
4. **Inefficient Retrieval**: Finding semantically related thoughts requires manual navigation

### Why This Matters

1. **Long-Term Memory**: AI systems need persistent memory to learn from past interactions
2. **Semantic Navigation**: Users should be able to find related thoughts by meaning, not just location
3. **Pattern Recognition**: The system should identify recurring themes and workflows
4. **Cognitive Continuity**: Each session should build upon previous knowledge, not start from scratch

### Proposed Solution

Implement a **PostgreSQL + pgvector "Hippocampus"** that:
- Stores every "Thought Pixel" ever generated with its vector embedding
- Uses HNSW indexes for sub-50ms semantic similarity search
- Maps high-dimensional vector similarity back to 2D Hilbert coordinates
- Enables "Semantic Drag" (Middle Mouse + Shift) to retrieve related thoughts
- Visualizes "Memory Beams" connecting current cursor to historic locations

---

## Technical Approach

### Why PostgreSQL + pgvector?

**Advantages**:
- **Production-Grade**: Battle-tested, ACID compliant, highly scalable
- **pgvector Extension**: Native support for high-dimensional vector operations
- **HNSW Indexes**: Hierarchical Navigable Small World for <50ms similarity search
- **Cosine Distance**: Optimized operator (`<=>`) for semantic similarity
- **Binary Quantization**: 32x storage reduction for space-efficient containers
- **Mature Ecosystem**: Backup, replication, monitoring tools

**Performance Targets**:
- **Retrieval Latency**: <50ms for semantic neighborhood queries
- **Storage Efficiency**: ~1KB per thought pixel (with quantization)
- **Throughput**: 1000+ stores/second, 100+ retrievals/second
- **Scalability**: Millions of thought pixels with linear performance degradation

### Schema Design

```sql
-- Core thought_pixels table
CREATE TABLE thought_pixels (
    id SERIAL PRIMARY KEY,
    token_id INTEGER NOT NULL,
    token TEXT NOT NULL,
    embedding vector(1536) NOT NULL,  -- OpenAI embedding dimension
    hilbert_x FLOAT NOT NULL,          -- Normalized 0-1
    hilbert_y FLOAT NOT NULL,          -- Normalized 0-1
    layer INTEGER DEFAULT 0,
    activation FLOAT DEFAULT 1.0,
    session_id TEXT NOT NULL,
    timestamp FLOAT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- HNSW index for fast similarity search
CREATE INDEX thought_pixels_embedding_idx 
ON thought_pixels USING hnsw (embedding vector_cosine_ops);

-- Session index for temporal queries
CREATE INDEX thought_pixels_session_idx 
ON thought_pixels(session_id);

-- Timestamp index for chronological queries
CREATE INDEX thought_pixels_timestamp_idx 
ON thought_pixels(timestamp DESC);
```

### Why 1536-Dimensional Vectors?

**Rationale**:
- **OpenAI Compatibility**: Matches text-embedding-ada-002 dimensionality
- **Rich Semantics**: Sufficient dimensionality to capture complex semantic relationships
- **Industry Standard**: Widely adopted, well-tested, mature tooling
- **Future-Proof**: Compatible with most modern embedding models

**Alternative**: Custom embeddings from local models (e.g., sentence-transformers)

### Semantic Retrieval Algorithm

```python
def recall_semantic_neighborhood(
    query_vector: np.ndarray,
    limit: int = 100,
    threshold: float = 0.0,
    exclude_session: str = None
) -> List[Dict]:
    """
    Retrieve pixels from the past that 'vibe' with current thoughts.
    
    Uses pgvector's cosine distance operator (<=>) for efficient search.
    Cosine similarity = 1 - cosine_distance
    """
    query = """
    SELECT 
        token_id, token, hilbert_x, hilbert_y, layer, activation, 
        session_id, timestamp, embedding,
        1 - (embedding <=> %s) as similarity
    FROM thought_pixels
    WHERE 1 - (embedding <=> %s) >= %s
    """
    
    if exclude_session:
        query += " AND session_id != %s"
    
    query += " ORDER BY embedding <=> %s LIMIT %s"
    
    # Execute query with parameters
    # Returns results sorted by semantic similarity (descending)
```

### Memory Beam Visualization

**Concept**: Draw "Cyan lines" connecting cursor to semantically related historic locations

**Algorithm**:
```python
def get_memory_beam(
    query_vector: np.ndarray,
    current_x: float,
    current_y: float,
    limit: int = 20
) -> List[Dict]:
    """
    Get memory beam for visualization.
    Combines semantic similarity with spatial proximity.
    """
    memories = recall_semantic_neighborhood(query_vector, limit=limit)
    
    # Calculate spatial distance
    for memory in memories:
        dx = memory['hilbert_x'] - current_x
        dy = memory['hilbert_y'] - current_y
        memory['spatial_distance'] = sqrt(dx*dx + dy*dy)
    
    # Weighted scoring: 70% semantic, 30% spatial
    memories.sort(
        key=lambda m: (m['similarity'] * 0.7) + (1.0 / (m['spatial_distance'] + 0.01) * 0.3),
        reverse=True
    )
    
    return memories
```

**Visual Implementation**:
- **Cyan Lines**: Connect cursor to retrieved memory locations
- **Ghost Pixels**: Low-opacity (0.3) rendering of historic thoughts
- **Similarity Glow**: Brightness indicates semantic similarity
- **Temporal Fade**: Older memories appear more transparent

---

## Integration Points

### 1. LM Studio Bridge Integration

**Current Flow**:
```
LM Studio → LMStudioBridge → Evolution Daemon → Infinite Map
```

**Enhanced Flow**:
```
LM Studio → LMStudioBridge → Vector Memory Daemon → PostgreSQL
                          ↓
                    Evolution Daemon → Infinite Map
```

**Implementation**:
```python
# In LMStudioBridge
async def send_token_activation(self, token: str, token_id: int, 
                                embedding: np.ndarray, layer: int = 0):
    """Send token activation to both compositor and memory daemon"""
    
    # Send to compositor (existing)
    message = self.create_token_message(token, token_id, embedding, layer)
    await self.send_to_compositor(message)
    
    # Send to memory daemon (new)
    thought = ThoughtPixel(
        token_id=token_id,
        token=token,
        embedding=embedding,
        hilbert_x=message['payload']['hilbert_position'][0],
        hilbert_y=message['payload']['hilbert_position'][1],
        layer=layer,
        timestamp=time.time()
    )
    await self.send_to_memory_daemon(thought)
```

### 2. InputInteractionAgent Integration

**Semantic Drag Gesture**:
- **Trigger**: Middle Mouse + Shift + Drag
- **Action**: Query memory daemon for semantically related thoughts
- **Visual**: Draw memory beams to retrieved locations

**Implementation**:
```python
# In InputInteractionAgent
async def handle_semantic_drag(self, start_pos: Tuple[float, float], 
                               end_pos: Tuple[float, float]):
    """Handle semantic drag gesture"""
    
    # Get current context embedding
    query_vector = await self.get_context_embedding()
    
    # Query memory daemon
    memories = await self.recall_memories(
        query_vector=query_vector,
        current_x=end_pos[0],
        current_y=end_pos[1],
        limit=20
    )
    
    # Send memory beam data to renderer
    await self.send_memory_beam(memories)
```

### 3. GraphicsRenderingAgent Integration

**Memory Beam Shader**:
```wgsl
// WGSL shader for memory beam visualization
struct MemoryBeam {
    start_pos: vec2<f32>,
    end_pos: vec2<f32>,
    similarity: f32,
    timestamp: f32,
};

@group(0) @binding(0) var<uniform> beams: array<MemoryBeam>;

@vertex
fn vs_main(@builtin(vertex_index) vertex_index: u32) -> VertexOutput {
    // Generate line geometry for each memory beam
    // Apply glow effect based on similarity
}

@fragment
fn fs_main(in: VertexOutput) -> @location(0) vec4<f32> {
    // Cyan color with varying opacity based on similarity
    let similarity = beams[in.instance_index].similarity;
    let alpha = similarity * 0.8;
    return vec4<f32>(0.0, 1.0, 1.0, alpha);
}
```

### 4. PixiJS Integration

**Memory Beam RenderGroup**:
```typescript
// PixiJS memory beam visualization
class MemoryBeamRenderer {
    private beams: Graphics[] = [];
    
    renderMemoryBeams(memories: Memory[]): void {
        memories.forEach(memory => {
            const beam = new Graphics();
            beam.lineStyle(2, 0x00FFFF, memory.similarity * 0.8);
            beam.moveTo(this.cursorX, this.cursorY);
            beam.lineTo(memory.hilbertX * canvasWidth, memory.hilbertY * canvasHeight);
            this.container.addChild(beam);
            this.beams.push(beam);
        });
    }
    
    renderGhostPixels(memories: Memory[]): void {
        memories.forEach(memory => {
            const ghost = new Graphics();
            ghost.beginFill(0x00FFFF, memory.similarity * 0.3);
            ghost.drawCircle(
                memory.hilbertX * canvasWidth,
                memory.hilbertY * canvasHeight,
                5
            );
            ghost.endFill();
            this.container.addChild(ghost);
        });
    }
}
```

---

## Success Criteria

### Functional Requirements

- [ ] VectorMemoryDaemon with PostgreSQL + pgvector backend
- [ ] ThoughtPixel dataclass with embedding storage
- [ ] Semantic neighborhood retrieval with cosine similarity
- [ ] HNSW index for <50ms query performance
- [ ] Memory beam visualization (cyan lines)
- [ ] Ghost pixel rendering (low-opacity historic thoughts)
- [ ] Semantic drag gesture (Middle Mouse + Shift)
- [ ] Session-based memory organization
- [ ] Temporal decay for old memories
- [ ] Binary quantization support (optional)

### Performance Requirements

- [ ] Memory retrieval <50ms (target)
- [ ] Memory storage <10ms (target)
- [ ] Database size <1GB (after 1M thought pixels)
- [ ] Throughput: 1000+ stores/second
- [ ] Concurrent queries: 100+ QPS

### Quality Requirements

- [ ] Test coverage >85%
- [ ] No data loss (ACID compliance)
- [ ] Graceful degradation if database unavailable
- [ ] Memory leak prevention
- [ ] Proper error handling and logging

### Integration Requirements

- [ ] LMStudioBridge integration complete
- [ ] InputInteractionAgent integration complete
- [ ] GraphicsRenderingAgent integration complete
- [ ] PixiJS integration complete
- [ ] EvolutionDaemon integration complete

---

## Implementation Plan

### Week 1: Core Memory System (January 22 - January 28)

**Tasks**:
1. ✅ Create PostgreSQL schema with pgvector extension
2. ✅ Implement VectorMemoryDaemon class
3. ✅ Implement ThoughtPixel dataclass
4. ✅ Implement semantic neighborhood retrieval
5. ✅ Add HNSW indexing for performance
6. ✅ Implement Unix socket server
7. [ ] Write unit tests (>85% coverage)
8. [ ] Create performance benchmarks
9. [ ] Add setup scripts for PostgreSQL/pgvector

### Week 2: Integration & Visualization (January 29 - February 5)

**Tasks**:
1. [ ] Integrate with LMStudioBridge for token storage
2. [ ] Implement semantic drag gesture in InputInteractionAgent
3. [ ] Add memory beam shader to GraphicsRenderingAgent
4. [ ] Implement PixiJS memory beam renderer
5. [ ] Add ghost pixel visualization
6. [ ] Integrate with EvolutionDaemon
7. [ ] Write integration tests
8. [ ] Create end-to-end demo
9. [ ] Document usage and API

---

## Visual Impact

### Memory Beam Visualization

**Cyan Lines**:
- Connect cursor to semantically related historic locations
- Opacity based on similarity score (0.3 - 0.8)
- Glow effect for high-similarity memories
- Animated pulse for active retrieval

**Ghost Pixels**:
- Low-opacity (0.3) circles at historic locations
- Size based on activation level
- Color based on layer (multi-layer visualization)
- Temporal fade for older memories

### Example Scene

```
User performs "Semantic Drag" (Middle Mouse + Shift):

Cursor Position: (0.5, 0.5)
Query Vector: [0.1, 0.2, ..., 0.9]  // Current context

Retrieved Memories:
1. "function" (0.92 similarity) at (0.3, 0.4)
   ── Cyan line, bright glow
2. "class" (0.87 similarity) at (0.6, 0.7)
   ── Cyan line, medium glow
3. "variable" (0.81 similarity) at (0.2, 0.8)
   ── Cyan line, dim glow
4. "import" (0.75 similarity) at (0.9, 0.1)
   ── Faint cyan line

Ghost Pixels:
- Semi-transparent circles at each memory location
- Size: 5-10px based on activation
- Color: Cyan with slight variation per layer
```

---

## Risks & Mitigations

### Risk 1: PostgreSQL Performance Degradation

**Mitigation**:
- Use HNSW indexes for fast similarity search
- Implement connection pooling
- Add query optimization (EXPLAIN ANALYZE)
- Monitor query performance metrics
- Implement caching layer for frequent queries

### Risk 2: Storage Growth

**Mitigation**:
- Implement binary quantization (32x reduction)
- Add temporal decay (archive old memories)
- Implement session-based pruning
- Provide data export/backup tools
- Monitor storage usage and alert thresholds

### Risk 3: Embedding Generation Overhead

**Mitigation**:
- Cache embeddings for repeated tokens
- Use local embedding models (sentence-transformers)
- Implement batch embedding generation
- Fallback to simple token embeddings if needed
- Asynchronous embedding pipeline

### Risk 4: Integration Complexity

**Mitigation**:
- Modular design (each component independent)
- Clear interface contracts (Unix socket protocol)
- Integration tests for each connection
- Incremental rollout (test each integration separately)
- Comprehensive error handling and logging

---

## Open Questions

1. **Embedding Dimensionality**: 1536 (OpenAI) or custom local model? (Proposed: 1536 for compatibility)
2. **Storage Limit**: Maximum number of thought pixels? (Proposed: 1M with pruning)
3. **Retention Policy**: How long to keep memories? (Proposed: 90 days with decay)
4. **Similarity Threshold**: Minimum for retrieval? (Proposed: 0.7 default, configurable)
5. **Quantization**: Enable binary quantization by default? (Proposed: Optional, disabled by default)

---

## Dependencies

### Required
- PostgreSQL 14+ (with pgvector extension)
- psycopg2-binary (Python PostgreSQL adapter)
- pgvector (Python pgvector client)
- NumPy (for vector operations)
- Existing components: LMStudioBridge, InputInteractionAgent, GraphicsRenderingAgent

### Optional
- OpenAI API (for embeddings)
- sentence-transformers (local embeddings)
- Redis (caching layer)
- Prometheus (monitoring)

---

## Timeline

**Duration**: 2 weeks (January 22 - February 5, 2026)

**Milestones**:
- Week 1: Core memory system complete
- Week 2: Integration & visualization complete

**Confidence**: 0.92 (Very High)

---

## Sign-Off

**Proposed by**: Kilo Code  
**Phase**: Phase 26  
**Status**: Ready for implementation

---

*This proposal follows the Spec-First Development principle and maintains Glass Box AI transparency.*
